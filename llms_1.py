# -*- coding: utf-8 -*-
"""LLMS_1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eKb56p5_RS0MHVn6Nm75Ui1UCLBNE10W
"""

!nvidia-smi

import transformers

from transformers import AutoModelForCausalLM , AutoTokenizer

model = AutoModelForCausalLM.from_pretrained("microsoft/Phi-3-mini-4k-instruct", device_map = "cuda", torch_dtype = "auto")

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-3-mini-4k-instruct")

from transformers  import pipeline

generator = pipeline("text-generation", model = model, tokenizer = tokenizer, max_length = 500)

generator("create queastions and answers list topic from the python")

messages = [{"role": "user", "content": "Create a funny joke about python."}]

res = generator(messages)

res[0]['generated_text']

res[0]

res = generator("generate queastion and answers for python list")

res1 = res[0]['generated_text']

final = res1.replace(". ", ".\n")

print(final)

